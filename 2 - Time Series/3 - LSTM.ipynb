{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install neptune \n!pip install lightning","metadata":{"execution":{"iopub.status.busy":"2023-05-14T12:24:48.653445Z","iopub.execute_input":"2023-05-14T12:24:48.653811Z","iopub.status.idle":"2023-05-14T12:25:32.892459Z","shell.execute_reply.started":"2023-05-14T12:24:48.653784Z","shell.execute_reply":"2023-05-14T12:25:32.891312Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting neptune\n  Downloading neptune-1.2.0-py3-none-any.whl (448 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m448.1/448.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.10/site-packages (from neptune) (0.18.3)\nRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from neptune) (8.1.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from neptune) (5.9.4)\nRequirement already satisfied: oauthlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from neptune) (3.2.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from neptune) (1.16.0)\nCollecting swagger-spec-validator>=2.7.4\n  Downloading swagger_spec_validator-3.0.3-py2.py3-none-any.whl (27 kB)\nRequirement already satisfied: Pillow>=1.1.6 in /opt/conda/lib/python3.10/site-packages (from neptune) (9.5.0)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from neptune) (1.26.15)\nRequirement already satisfied: GitPython>=2.0.8 in /opt/conda/lib/python3.10/site-packages (from neptune) (3.1.31)\nCollecting bravado<12.0.0,>=11.0.0\n  Downloading bravado-11.0.3-py2.py3-none-any.whl (38 kB)\nRequirement already satisfied: requests-oauthlib>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from neptune) (1.3.1)\nRequirement already satisfied: PyJWT in /opt/conda/lib/python3.10/site-packages (from neptune) (2.6.0)\nRequirement already satisfied: boto3>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from neptune) (1.26.100)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from neptune) (21.3)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from neptune) (1.5.3)\nRequirement already satisfied: requests>=2.20.0 in /opt/conda/lib/python3.10/site-packages (from neptune) (2.28.2)\nRequirement already satisfied: websocket-client!=1.0.0,>=0.35.0 in /opt/conda/lib/python3.10/site-packages (from neptune) (1.5.1)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3>=1.16.0->neptune) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3>=1.16.0->neptune) (0.6.0)\nCollecting botocore<1.30.0,>=1.29.100\n  Downloading botocore-1.29.133-py3-none-any.whl (10.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting monotonic\n  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from bravado<12.0.0,>=11.0.0->neptune) (2.8.2)\nRequirement already satisfied: simplejson in /opt/conda/lib/python3.10/site-packages (from bravado<12.0.0,>=11.0.0->neptune) (3.19.1)\nRequirement already satisfied: msgpack in /opt/conda/lib/python3.10/site-packages (from bravado<12.0.0,>=11.0.0->neptune) (1.0.5)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from bravado<12.0.0,>=11.0.0->neptune) (4.5.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from bravado<12.0.0,>=11.0.0->neptune) (6.0)\nCollecting bravado-core>=5.16.1\n  Downloading bravado_core-5.17.1-py2.py3-none-any.whl (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython>=2.0.8->neptune) (4.0.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20.0->neptune) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20.0->neptune) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20.0->neptune) (2022.12.7)\nRequirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from swagger-spec-validator>=2.7.4->neptune) (4.17.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->neptune) (3.0.9)\nRequirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas->neptune) (1.23.5)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->neptune) (2023.3)\nCollecting jsonref\n  Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune) (5.0.0)\nRequirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (22.2.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (0.19.3)\nRequirement already satisfied: isoduration in /opt/conda/lib/python3.10/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (20.11.0)\nRequirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.10/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (2.0)\nRequirement already satisfied: fqdn in /opt/conda/lib/python3.10/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (1.5.1)\nRequirement already satisfied: uri-template in /opt/conda/lib/python3.10/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (1.2.0)\nCollecting rfc3987\n  Downloading rfc3987-1.3.8-py2.py3-none-any.whl (13 kB)\nRequirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (0.1.4)\nRequirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.10/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (1.13)\nRequirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from isoduration->jsonschema->swagger-spec-validator>=2.7.4->neptune) (1.2.3)\nInstalling collected packages: rfc3987, monotonic, jsonref, swagger-spec-validator, botocore, bravado-core, bravado, neptune\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.29.76\n    Uninstalling botocore-1.29.76:\n      Successfully uninstalled botocore-1.29.76\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naiobotocore 2.5.0 requires botocore<1.29.77,>=1.29.76, but you have botocore 1.29.133 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed botocore-1.29.133 bravado-11.0.3 bravado-core-5.17.1 jsonref-1.1.0 monotonic-1.6 neptune-1.2.0 rfc3987-1.3.8 swagger-spec-validator-3.0.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting lightning\n  Downloading lightning-2.0.2-py3-none-any.whl (1.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: fsspec[http]<2025.0,>2021.06.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2023.4.0)\nCollecting inquirer<5.0,>=2.10.0\n  Downloading inquirer-3.1.3-py3-none-any.whl (18 kB)\nRequirement already satisfied: arrow<3.0,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.2.3)\nRequirement already satisfied: rich<15.0,>=12.3.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (13.3.3)\nCollecting dateutils<2.0\n  Downloading dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\nRequirement already satisfied: requests<4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.28.2)\nRequirement already satisfied: Jinja2<5.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (3.1.2)\nRequirement already satisfied: uvicorn<2.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.21.1)\nRequirement already satisfied: PyYAML<8.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (6.0)\nRequirement already satisfied: traitlets<7.0,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (5.9.0)\nRequirement already satisfied: lightning-utilities<2.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.8.0)\nCollecting starsessions<2.0,>=1.2.1\n  Downloading starsessions-1.3.0-py3-none-any.whl (10 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\nRequirement already satisfied: psutil<7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (5.9.4)\nRequirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.23.5)\nRequirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning) (2.0.1.post0)\nRequirement already satisfied: urllib3<3.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.26.15)\nRequirement already satisfied: click<10.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (8.1.3)\nRequirement already satisfied: websocket-client<3.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.5.1)\nRequirement already satisfied: torch<4.0,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.0.0+cpu)\nRequirement already satisfied: starlette in /opt/conda/lib/python3.10/site-packages (from lightning) (0.26.1)\nCollecting lightning-cloud>=0.5.34\n  Downloading lightning_cloud-0.5.36-py3-none-any.whl (562 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.12.2)\nRequirement already satisfied: websockets<12.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (11.0.2)\nRequirement already satisfied: typing-extensions<6.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.5.0)\nRequirement already satisfied: torchmetrics<2.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.11.4)\nCollecting fastapi<0.89.0,>=0.69.0\n  Downloading fastapi-0.88.0-py3-none-any.whl (55 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting croniter<1.4.0,>=1.3.0\n  Downloading croniter-1.3.14-py2.py3-none-any.whl (18 kB)\nCollecting deepdiff<8.0,>=5.7.0\n  Downloading deepdiff-6.3.0-py3-none-any.whl (69 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pydantic<4.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.10.7)\nRequirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.64.1)\nRequirement already satisfied: python-dateutil>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from arrow<3.0,>=1.2.0->lightning) (2.8.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4<6.0,>=4.8.0->lightning) (2.4)\nRequirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from dateutils<2.0->lightning) (2023.3)\nCollecting ordered-set<4.2.0,>=4.0.2\n  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\nCollecting starlette\n  Downloading starlette-0.22.0-py3-none-any.whl (64 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette->lightning) (3.6.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (3.8.4)\nRequirement already satisfied: blessed>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from inquirer<5.0,>=2.10.0->lightning) (1.20.0)\nCollecting python-editor>=1.0.4\n  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\nCollecting readchar>=3.0.6\n  Downloading readchar-4.0.5-py3-none-any.whl (8.5 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2<5.0->lightning) (2.1.2)\nCollecting python-multipart\n  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from lightning-cloud>=0.5.34->lightning) (1.16.0)\nRequirement already satisfied: pyjwt in /opt/conda/lib/python3.10/site-packages (from lightning-cloud>=0.5.34->lightning) (2.6.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->lightning) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<4.0->lightning) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<4.0->lightning) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<4.0->lightning) (3.4)\nRequirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<15.0,>=12.3.0->lightning) (2.2.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<15.0,>=12.3.0->lightning) (2.15.0)\nRequirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from starsessions<2.0,>=1.2.1->lightning) (2.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (1.11.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.11.0->lightning) (3.11.0)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn<2.0->lightning) (0.14.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (22.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.8.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.3.3)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette->lightning) (1.3.0)\nRequirement already satisfied: wcwidth>=0.1.4 in /opt/conda/lib/python3.10/site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (0.2.6)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<15.0,>=12.3.0->lightning) (0.1.2)\nRequirement already satisfied: setuptools>=41.0 in /opt/conda/lib/python3.10/site-packages (from readchar>=3.0.6->inquirer<5.0,>=2.10.0->lightning) (59.8.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=1.11.0->lightning) (1.3.0)\nInstalling collected packages: python-editor, readchar, python-multipart, ordered-set, starlette, inquirer, deepdiff, dateutils, croniter, starsessions, fastapi, lightning-cloud, lightning\n  Attempting uninstall: starlette\n    Found existing installation: starlette 0.26.1\n    Uninstalling starlette-0.26.1:\n      Successfully uninstalled starlette-0.26.1\n  Attempting uninstall: fastapi\n    Found existing installation: fastapi 0.95.0\n    Uninstalling fastapi-0.95.0:\n      Successfully uninstalled fastapi-0.95.0\nSuccessfully installed croniter-1.3.14 dateutils-0.6.12 deepdiff-6.3.0 fastapi-0.88.0 inquirer-3.1.3 lightning-2.0.2 lightning-cloud-0.5.36 ordered-set-4.1.0 python-editor-1.0.4 python-multipart-0.0.6 readchar-4.0.5 starlette-0.22.0 starsessions-1.3.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport os\nimport torch\nimport torchvision\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader, random_split\nimport lightning as L\nimport neptune.new as neptune\nfrom torchmetrics import Accuracy\nfrom torchmetrics import AveragePrecision\nimport os\nimport pandas as pd\nfrom lightning.pytorch.callbacks import TQDMProgressBar\nimport math\nimport random","metadata":{"execution":{"iopub.status.busy":"2023-05-14T12:25:32.895110Z","iopub.execute_input":"2023-05-14T12:25:32.895490Z","iopub.status.idle":"2023-05-14T12:25:52.132613Z","shell.execute_reply.started":"2023-05-14T12:25:32.895455Z","shell.execute_reply":"2023-05-14T12:25:52.131493Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/tmp/ipykernel_34/3539159077.py:9: NeptuneDeprecationWarning: You're importing the Neptune client library via the deprecated `neptune.new` module, which will be removed in a future release. Import directly from `neptune` instead.\n  import neptune.new as neptune\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data pre proccessing","metadata":{}},{"cell_type":"code","source":"def norm(data):\n    return (data - data.min()) / (data.max() - data.min())","metadata":{"execution":{"iopub.status.busy":"2023-05-14T12:30:55.406892Z","iopub.execute_input":"2023-05-14T12:30:55.407423Z","iopub.status.idle":"2023-05-14T12:30:55.417055Z","shell.execute_reply.started":"2023-05-14T12:30:55.407362Z","shell.execute_reply":"2023-05-14T12:30:55.415224Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\np = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/'\ntrain_dir = p + '/train'\n\npath = f'{train_dir}/tdcsfog'\nfiles = [os.path.join(path, f) for f in os.listdir(path) if f.endswith('.csv')]\ntdcsfog_df = pd.concat([pd.read_csv(f).assign(Id=f.split('/')[-1].split('.')[0]) for f in files])\ntdcsfog_df.index=range(len(tdcsfog_df))\n\npath = f'{train_dir}/defog'\nfiles = [os.path.join(path, f) for f in os.listdir(path) if f.endswith('.csv')]\ndefog_df = pd.concat([pd.read_csv(f).assign(Id=f.split('/')[-1].split('.')[0]) for f in files])\ndefog_df.index=range(len(defog_df))\n# normalize \ndefog_df['AccV']=defog_df['AccV']/9.8\ndefog_df['AccML']=defog_df['AccML']/9.8\ndefog_df['AccAP']=defog_df['AccAP']/9.8\n\ndefog_df['AccV']=norm(defog_df['AccV'])\ndefog_df['AccML']=norm(defog_df['AccML'])\ndefog_df['AccAP']=norm(defog_df['AccAP'])\n\ntdcsfog_df['AccV']=norm(tdcsfog_df['AccV'])\ntdcsfog_df['AccML']=norm(tdcsfog_df['AccML'])\ntdcsfog_df['AccAP']=norm(tdcsfog_df['AccAP'])\n\n\ndf = pd.concat([tdcsfog_df,defog_df])\n\ntdcsfog_metadata = pd.read_csv(p+'/tdcsfog_metadata.csv')\ndefog_metadata = pd.read_csv(p+'/defog_metadata.csv')\nmetadata= pd.concat([tdcsfog_metadata,defog_metadata])\ndf = df.merge(metadata, on='Id', how='inner')\nencoder = LabelEncoder()\ndf['Id']=encoder.fit_transform(df['Id'])","metadata":{"execution":{"iopub.status.busy":"2023-05-14T12:30:56.534001Z","iopub.execute_input":"2023-05-14T12:30:56.534411Z","iopub.status.idle":"2023-05-14T12:31:43.695581Z","shell.execute_reply.started":"2023-05-14T12:30:56.534353Z","shell.execute_reply":"2023-05-14T12:31:43.694274Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def get_idx_of_lables(df):\n    any_ones = df[['StartHesitation', 'Turn', 'Walking']].eq(1).any(axis=1)\n    idx_with_ones = df[any_ones].index\n    return idx_with_ones\n\ndef wind(df, window_size_range):\n    lable_indexes = list(get_idx_of_lables(df))\n    times = np.array(df['Time'])\n\n    lable_indexes = np.array(lable_indexes)\n    mask = np.where(lable_indexes[1:] - lable_indexes[:-1] != 1)[0]\n\n    start_segments = lable_indexes[np.concatenate((np.array([0]), mask + 1))]\n    end_segments = lable_indexes[np.concatenate((mask, np.array([len(lable_indexes) - 1])))]\n\n    res = []\n\n    for start, end in zip(start_segments, end_segments):\n        window_size = random.randint(int(window_size_range*0.8), int(window_size_range*1.2))\n        res.extend(times[max(0, start - window_size // 2):start])\n        res.extend(lable_indexes[start:end+1])\n        res.extend(times[end:min(len(times)-1, end + window_size // 4)])\n\n    return res\n\ndef window(df, window_size):\n    win_has_label_idx = wind(df, window_size)\n    return df.iloc[win_has_label_idx]\n\nwindowed_df = pd.concat([window(tdcsfog_df,256),window(defog_df,200)])\ntdcsfog_metadata = pd.read_csv(p + '/tdcsfog_metadata.csv')\ndefog_metadata = pd.read_csv(p + '/defog_metadata.csv')\nmetadata= pd.concat([tdcsfog_metadata,defog_metadata])\nwindowed_df = windowed_df.merge(metadata, on='Id', how='inner')\nencoder = LabelEncoder()\nwindowed_df['Id']=encoder.fit_transform(windowed_df['Id'])","metadata":{"execution":{"iopub.status.busy":"2023-05-14T12:31:43.698004Z","iopub.execute_input":"2023-05-14T12:31:43.698482Z","iopub.status.idle":"2023-05-14T12:31:48.200305Z","shell.execute_reply.started":"2023-05-14T12:31:43.698439Z","shell.execute_reply":"2023-05-14T12:31:48.198887Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class fogDataset(Dataset):\n    def __init__(self, df, ds_type=None):\n        self.ds_type = ds_type\n        self.df = df      \n        self.features = ['AccV', 'AccML', 'AccAP','Angle']\n        if ds_type == \"self\":\n            self.labels = ['AccVAboveAverage', 'AccMLAboveAverage', 'AccAPAboveAverage']\n        else:\n            self.labels = ['StartHesitation', 'Turn' , 'Walking']\n    \n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        record = self.df.iloc[idx]\n        y = torch.Tensor(record[self.labels])\n        x = torch.Tensor(record[self.features])        \n     \n        return x,y\n    \n    def get_head(self):\n        return self.df.head()\n        ","metadata":{"execution":{"iopub.status.busy":"2023-05-14T12:31:48.202310Z","iopub.execute_input":"2023-05-14T12:31:48.202742Z","iopub.status.idle":"2023-05-14T12:31:48.214710Z","shell.execute_reply.started":"2023-05-14T12:31:48.202711Z","shell.execute_reply":"2023-05-14T12:31:48.213087Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class dataset_build_test(Dataset):\n    def __init__(self,x):\n        self.id_num = x[\"Id\"].to_numpy()\n        cols = ['AccV', 'AccML', 'AccAP', 'Angle']\n        self.x = torch.tensor(x[cols].to_numpy(),dtype=torch.float32)\n        self.len = x.shape[0]\n\n    def __getitem__(self,idx):\n        return self.x[idx],self.id_num[idx]\n  \n    def __len__(self):\n        return self.len","metadata":{"execution":{"iopub.status.busy":"2023-05-14T12:31:48.218018Z","iopub.execute_input":"2023-05-14T12:31:48.219191Z","iopub.status.idle":"2023-05-14T12:31:48.237607Z","shell.execute_reply.started":"2023-05-14T12:31:48.219108Z","shell.execute_reply":"2023-05-14T12:31:48.236330Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GroupShuffleSplit\nfrom torch.utils.data import Subset\n\n\nX = windowed_df.drop(['AccV', 'AccML', 'AccAP'], axis=1)\ny = windowed_df[['AccV', 'AccML', 'AccAP']]\n\ngss = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n\ntrain_idx, val_idx = next(gss.split(X, y, windowed_df['Subject']))\ntrain_df,val_df =windowed_df.iloc[train_idx],df.iloc[val_idx]\n\ntrain_df['Angle'] = np.arctan2(train_df['AccAP'], train_df['AccV'])\nval_df['Angle'] = np.arctan2(val_df['AccAP'],val_df['AccV'])\n\ntrain_ds = fogDataset(train_df)\nvalidation_ds = fogDataset(val_df)\n\nlen(train_df)/len(windowed_df),len(val_df)/len(windowed_df)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T12:31:48.239039Z","iopub.execute_input":"2023-05-14T12:31:48.239440Z","iopub.status.idle":"2023-05-14T12:31:59.978500Z","shell.execute_reply.started":"2023-05-14T12:31:48.239409Z","shell.execute_reply":"2023-05-14T12:31:59.974680Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/2018393485.py:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  train_df['Angle'] = np.arctan2(train_df['AccAP'], train_df['AccV'])\n/tmp/ipykernel_34/2018393485.py:14: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  val_df['Angle'] = np.arctan2(val_df['AccAP'],val_df['AccV'])\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(0.5281437582443107, 0.47185624175568935)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Naive baselines","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import average_precision_score\n\ntrain_class_distribution = df[['StartHesitation', 'Turn', 'Walking']].sum() / len(df)\ntrain_naive_prediction = np.zeros_like(df[['StartHesitation', 'Turn', 'Walking']])\ntrain_naive_prediction[:, np.argmax(train_class_distribution)] = 1\ntrain_score = average_precision_score(df[['StartHesitation', 'Turn', 'Walking']], train_naive_prediction, average='weighted')\n\nprint(\"training score:\", train_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, MLPClassifier\nfrom sklearn.metrics import average_precision_score, log_loss\n\nrfc = RandomForestClassifier(n_estimators=100, random_state=42)\nrfc.fit(train_df[['AccV', 'AccML', 'AccAP', 'Angle']], train_df[['StartHesitation', 'Turn', 'Walking']])","metadata":{"execution":{"iopub.status.busy":"2023-05-14T12:31:59.981843Z","iopub.execute_input":"2023-05-14T12:31:59.983840Z","iopub.status.idle":"2023-05-14T12:37:40.865318Z","shell.execute_reply.started":"2023-05-14T12:31:59.983682Z","shell.execute_reply":"2023-05-14T12:37:40.864176Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"RandomForestClassifier(random_state=42)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"y_pred = rfc.predict(val_df[['AccV', 'AccML', 'AccAP', 'Angle']])\nmap_score = average_precision_score(val_df[['StartHesitation', 'Turn', 'Walking']].values, y_pred, average='weighted')\nprint(\"MAP Score:\", map_score)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T13:14:37.758457Z","iopub.execute_input":"2023-05-14T13:14:37.758891Z","iopub.status.idle":"2023-05-14T13:15:01.059985Z","shell.execute_reply.started":"2023-05-14T13:14:37.758857Z","shell.execute_reply":"2023-05-14T13:15:01.058617Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"MAP Score: 0.27313612367581697\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(train_df[['AccV', 'AccML', 'AccAP', 'Angle']], train_df[['StartHesitation', 'Turn', 'Walking']])\n\ny_pred = knn.predict(val_df[['AccV', 'AccML', 'AccAP', 'Angle']])\nmap_score = average_precision_score(val_df[['StartHesitation', 'Turn', 'Walking']].values, y_pred, average='weighted')\nprint(\"MAP Score:\", map_score)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:02:51.037038Z","iopub.execute_input":"2023-05-14T14:02:51.037520Z","iopub.status.idle":"2023-05-14T14:03:55.865491Z","shell.execute_reply.started":"2023-05-14T14:02:51.037484Z","shell.execute_reply":"2023-05-14T14:03:55.864190Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"MAP Score: 0.27613373766795807\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Self supervised dataset","metadata":{}},{"cell_type":"code","source":"def self_supervised_target(df):\n    AccVthreshold = df['AccV'].mean() \n    AccMLthreshold = df['AccML'].mean() \n    AccAPthreshold = df['AccAP'].mean() \n    df['AccVAboveAverage'] = df['AccV'].apply(lambda x: 1 if x > AccVthreshold else 0)\n    df['AccMLAboveAverage'] = df['AccML'].apply(lambda x: 1 if x > AccMLthreshold else 0)\n    df['AccAPAboveAverage'] = df['AccAP'].apply(lambda x: 1 if x > AccAPthreshold else 0)\n    return df\n\n\nss_train_df = self_supervised_target(train_df).drop(['StartHesitation', 'Turn', 'Walking', 'Id','Subject','Valid','Task'], axis=1)\nss_val_df = self_supervised_target(val_df).drop(['StartHesitation', 'Turn', 'Walking', 'Id','Subject','Valid','Task'], axis=1)\n\nss_train_ds = fogDataset(ss_train_df, \"self\")\nss_validation_ds = fogDataset(ss_val_df, \"self\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LSTM Model","metadata":{}},{"cell_type":"code","source":"def train_model(model,tags,epochs,batch_size,lr):\n    trainer = L.Trainer(\n        callbacks=[TQDMProgressBar(refresh_rate=100)],\n        accelerator='auto',\n        max_epochs=epochs,\n        devices=1,\n    )\n    run = neptune.init_run(\n        project=\"sadotal/ML-task2\",\n        api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJmMjIwNjBjMS1kMDhhLTQ4MzctYmIwZS05ZDUyY2E2ZjZiM2QifQ==\",)\n    \n    run[\"sys/tags\"].add(tags)\n    run[\"config/lr\"]=lr\n    run[\"config/epochs\"]=trainer.max_epochs\n    run[\"config/batch_size\"]=batch_size\n    model.run=run\n    model.lr=lr\n    trainer.fit(model,model.train_loader,model.val_loader)\n    print('===vaidate===')\n    trainer.validate(model,model.val_loader)\n    print(trainer.callback_metrics['val_loss'])\n    val_loss=trainer.callback_metrics['val_loss']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LSTM_Model(L.LightningModule):\n    def __init__(self, neptun_run=None) -> None:\n        super().__init__()\n        self.train_loader=None\n        self.val_loader=None\n        self.run=neptun_run\n        self.self_supervised = False\n        \n        self.val_accuracy = Accuracy(task=\"multiclass\", num_classes=3)\n        self.test_accuracy = Accuracy(task=\"multiclass\", num_classes=3)\n        \n        self.n_features = 4\n        self.hidden_size = 128\n        self.seq_len = 24\n        self.num_layers = 2\n        self.dropout = 0.5\n        self.learning_rate = 1e-4\n        \n#         self.reg_lambda = 0.01 # set regularization strength\n        \n        self.lstm = nn.LSTM(input_size=self.n_features, \n                            hidden_size=self.hidden_size,\n                            num_layers=self.num_layers, \n                            dropout=self.dropout, \n                            batch_first=True)\n        \n        self.linear1 = nn.Linear(self.hidden_size, 64)\n        self.fc = nn.Linear(64, 3)\n\n    def forward(self, x):\n        self.lstm(x) \n        lstm_out, _ = self.lstm(x)          \n        lstm_out = lstm_out.reshape(-1, self.hidden_size)\n        linear_out = F.relu(self.linear1(lstm_out))\n#         linear_out = F.dropout(linear_out, p=self.dropout) # add dropout\n        \n        fc_out = self.fc(linear_out)\n        output = F.log_softmax(fc_out, dim=1)\n\n        return output\n    \n    \n    \n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n     \n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        if self.self_supervised:\n            y = y.squeeze()    \n        y_hat = self(x)\n        \n        loss = F.cross_entropy(y_hat, y)\n#         l2_reg = torch.tensor(0.).to(device)\n#         for param in self.parameters():\n#             l2_reg += torch.norm(param)\n#         loss += self.reg_lambda * l2_reg\n        self.run['train/loss'].append(loss.item())\n        \n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch       \n        \n        if self.self_supervised:\n            y = y.squeeze()\n            \n        y_hat = self(x)  \n        loss = F.cross_entropy(y_hat, y)\n        y = y.int()\n        \n        accuracy=self.val_accuracy(y_hat, y).item()\n        \n        self.run['validation/loss'].append(loss.item())\n        self.run['validation/accuracy'].append(accuracy)\n        \n        self.log(\"val_loss\", loss , prog_bar=True,on_step=True)\n        self.log(\"val_acc\", accuracy , prog_bar=True,on_step=True)\n        \n        return loss\n    \n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        \n        if self.self_supervised:\n            y = y.squeeze()\n            \n        y_hat = self(x)\n        y = y.int()\n        loss = F.cross_entropy(y_hat, y)\n        \n        accuracy=self.test_accuracy(y_hat, y).item()\n        \n        self.run['test/loss'].append(loss.item())\n        self.run['test/accuracy'].append(accuracy)\n        \n        self.log(\"test_loss\", loss , prog_bar=True,on_step=True)\n        self.log(\"test_acc\", accuracy, prog_bar=True,on_step=True)\n        \n        return loss\n    \n    \n    def change_training_type(self, train_loader, val_loader, self_supervised=False):\n        self.train_loader=train_loader\n        self.val_loader=val_loader\n        if self_supervised:\n            self.self_supervised = True\n            self.fc = nn.Linear(64, 3)    \n        else:\n            self.fc = nn.Linear(64, 3)\n            self.self_supervised = False\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 256\ndevice='cuda'\nlr=1e-4\nepochs=1\ntrain_loader = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE,shuffle=False)\nval_loader = torch.utils.data.DataLoader(validation_ds, batch_size=BATCH_SIZE,shuffle=False)\n\n# ss_train_loader = torch.utils.data.DataLoader(ss_train_ds, batch_size=BATCH_SIZE,shuffle=False)\n# ss_val_loader = torch.utils.data.DataLoader(ss_validation_ds, batch_size=BATCH_SIZE,shuffle=False)\n\nmodel=LSTM_Model()\n\n# model.change_training_type(ss_train_loader,ss_val_loader, True)\n# train_model(model,['Self_Supervised'],1,BATCH_SIZE,lr)\n\nmodel.change_training_type(train_loader,val_loader)\ntrain_model(model,['main_training'],epochs,BATCH_SIZE,lr)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tests and plots","metadata":{}},{"cell_type":"code","source":"from torchmetrics import Precision\n\ndef precision(model,loader):\n    precision = Precision(task=\"multiclass\", num_classes=3).cuda()\n    precision_lst=[]\n    for batch_idx, (x, y) in enumerate(loader):\n        y_hat = model(x)\n        pred = torch.argmax(y_hat, dim=1)\n        actual = torch.argmax(y, dim=1)\n        precision_lst.append(precision(pred,actual))\n    return sum(precision_lst)/len(precision_lst) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f'precision is {precision(model,val_loader)}'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef plot_count(model,loader):\n    counter =  defaultdict(int)\n    for batch_idx, (x, y) in enumerate(val_loader):\n        y_hat = model(x)\n        pred = torch.argmax(y_hat, dim=1)\n        actual = torch.argmax(y, dim=1)    \n        for i,c in enumerate(actual):\n            if c==pred[i]:\n                counter[f'{c.item()} currect']+=1\n                counter[f'{c.item()} incurrect']+=0\n            else:\n                counter[f'{c.item()} incurrect']+=1\n                counter[f'{c.item()} currect']+=0\n    data = {\"Category\": list(counter.keys()), \"Values\": list(counter.values())}\n    dfplt = pd.DataFrame(data)\n    dfplt = dfplt.sort_values(by=\"Category\")\n    plt.figure(figsize=(12, 6))\n    sns.barplot(x=\"Category\", y=\"Values\", data=dfplt)\n    plt.show()\n            \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_count(model,val_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}